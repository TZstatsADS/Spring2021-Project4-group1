) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 16, maxdepth = 13, cp = 0.02253)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/lowDim_dataset.csv")
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
plotcp(m1)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
plotcp(m1)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/lowDim_dataset.csv")
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
data
data[, 2:]
data[, (2:)]
subset(data, select = -Y)]
subset(data, select = -y)
subset(data, select = -Y)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/lowDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
rpart.plot(m1)
plotcp(m1)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
rpart.plot(m2)
plotcp(m2)
abline(v = 16, lty = "dashed")
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 20, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
get_cp <- function(x) {
min <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
library(rsample)     # data splitting
library(dplyr)
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
data <- subset(data, select = -Y)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(caret)       # bagging
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(caret)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/lowDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(caret)
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
rpart.plot(m1)
plotcp(m1)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
rpart.plot(m2)
plotcp(m2)
abline(v = 16, lty = "dashed")
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 20, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
get_cp <- function(x) {
min <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 5, maxdepth = 16, cp = 0.0258)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(caret)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
m1
rpart.plot(m1)
plotcp(m1)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
rpart.plot(m2)
plotcp(m2)
abline(v = 6, lty = "dashed")
plotcp(m2)
abline(v = 6, lty = "dashed")
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 30, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
get_cp <- function(x) {
min <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(caret)
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
m1
rpart.plot(m1)
plotcp(m1)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
rpart.plot(m2)
plotcp(m2)
abline(v = 6, lty = "dashed")
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 30, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
get_cp <- function(x) {
min <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 18, maxdepth = 15, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 20, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 20, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
MSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 20, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 20, maxdepth = 15, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 20, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
setwd("/Users/my_love/Desktop/Applied Data Science/Project 4/Spring2021-Project4-project4group1/")
data <- read.csv(file = "data/highDim_dataset.csv")
data <- subset(data, select = -Y)
library(rsample)     # data splitting
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(caret)
set.seed(123)
data_split <- initial_split(data, prop = .7)
train <- training(data_split)
test  <- testing(data_split)
m1
m1 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova"
)
m1
rpart.plot(m1)
plotcp(m1)
m2 <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
rpart.plot(m2)
plotcp(m2)
abline(v = 6, lty = "dashed")
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 30, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
hyper_grid <- expand.grid(
minsplit = seq(5, 20, 1),
maxdepth = seq(8, 30, 1)
)
models <- list()
for (i in 1:nrow(hyper_grid)) {
# get minsplit, maxdepth values at row i
minsplit <- hyper_grid$minsplit[i]
maxdepth <- hyper_grid$maxdepth[i]
# train a model and store in the list
models[[i]] <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = minsplit, maxdepth = maxdepth)
)
}
get_cp <- function(x) {
min <- which.min(x$cptable[, "xerror"])
cp <- x$cptable[min, "CP"]
}
get_min_error <- function(x) {
min    <- which.min(x$cptable[, "xerror"])
xerror <- x$cptable[min, "xerror"]
}
hyper_grid %>%
mutate(
cp    = purrr::map_dbl(models, get_cp),
error = purrr::map_dbl(models, get_min_error)
) %>%
arrange(error) %>%
top_n(-5, wt = error)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 20, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
optimal_tree <- rpart(
formula = A ~ .,
data    = train,
method  = "anova",
control = list(minsplit = 11, maxdepth = 16, cp = 0.01)
)
pred <- predict(optimal_tree, newdata = test)
RMSE(pred = pred, obs = test$A)
